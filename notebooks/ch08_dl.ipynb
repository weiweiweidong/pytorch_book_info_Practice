{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sq7LWW1GyMr"
      },
      "source": [
        "# 8章　MNISTを使った数字認識"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4NAwf20QRbN"
      },
      "source": [
        "# 必要ライブラリの導入\n",
        "\n",
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIKc0rgJQRbQ"
      },
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4AKptKEQRbQ"
      },
      "source": [
        "# torch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJvhUX1QRbR"
      },
      "source": [
        "# warning表示off\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vlvZjd_y8fw"
      },
      "source": [
        "## 8.3 ReLU関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr0e6fNJztAr"
      },
      "source": [
        "# ReLU関数のグラフ\n",
        "\n",
        "relu = nn.ReLU()\n",
        "x_np = np.arange(-2, 2.1, 0.25)\n",
        "x = torch.tensor(x_np).float()\n",
        "y = relu(x)\n",
        "\n",
        "plt.plot(x.data, y.data)\n",
        "plt.title('ReLU関数')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuXnWk6jtpfW"
      },
      "source": [
        "## 8.4 GPU利用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9dK3ibfzWDW"
      },
      "source": [
        "### GPUチェック"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vMUHy9RGyNB"
      },
      "source": [
        "# デバイスの割り当て\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-koKiUTy8fx"
      },
      "source": [
        "# テスト用tensor変数x , y \n",
        "x_np = np.arange(-2.0, 2.1, 0.25)\n",
        "y_np = np.arange(-1.0, 3.1, 0.25)\n",
        "x = torch.tensor(x_np).float()\n",
        "y = torch.tensor(y_np).float()\n",
        "\n",
        "# xとyの間の演算\n",
        "z = x * y\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-VBUQL135T3"
      },
      "source": [
        "# 変数xをGPUに送る\n",
        "x = x.to(device)\n",
        "\n",
        "# 変数xとyの属性data, deviceの確認\n",
        "print('x: ', x.device)\n",
        "print('y: ', y.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOqHX2735yN"
      },
      "source": [
        "# この状態でxとyの演算をすると。。。\n",
        "\n",
        "z = x * y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qavPREnP359u"
      },
      "source": [
        "# yもGPUに送る\n",
        "y = y.to(device)\n",
        "\n",
        "# 今度は計算可能になる\n",
        "z = x * y\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S2H468hORq2"
      },
      "source": [
        "## 8.8 データ準備1 (データセットによる読み込み)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbjBR_ZAORq3"
      },
      "source": [
        "# ライブラリインポート\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# ダウンロード先ディレクトリ名\n",
        "data_root = './data'\n",
        "\n",
        "train_set0 = datasets.MNIST(\n",
        "    # 元データダウンロード先の指定\n",
        "    root = data_root,  \n",
        "    # 訓練データか検証データか\n",
        "    train = True,  \n",
        "    # 元データがない場合にダウンロードするか\n",
        "    download = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZDvzf2nSc8n"
      },
      "source": [
        "# ダウンロードしたファイルの確認\n",
        "\n",
        "!ls -lR ./data/MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTnvCClZh93k"
      },
      "source": [
        "# データ件数の確認\n",
        "print('データ件数: ', len(train_set0))\n",
        "\n",
        "# 最初の要素の取得\n",
        "image, label = train_set0[0]\n",
        "\n",
        "# データ型の確認\n",
        "print('入力データの型: ', type(image))\n",
        "print('正解データの型: ', type(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zax7TjeCORq5"
      },
      "source": [
        "# 入力データの画像表示\n",
        "\n",
        "plt.figure(figsize=(2,3))\n",
        "plt.title(f'{label}')\n",
        "plt.imshow(image, cmap='gray_r')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cltigf4xh95z"
      },
      "source": [
        "# 正解データ付きで、最初の20個をイメージ表示\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "for i in range(20):\n",
        "    ax = plt.subplot(2, 10, i + 1)\n",
        "    \n",
        "    # image と labelの取得\n",
        "    image, label = train_set0[i]\n",
        "    \n",
        "    # イメージ表示\n",
        "    plt.imshow(image, cmap='gray_r')\n",
        "    ax.set_title(f'{label}')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H69fmQI0ORq6"
      },
      "source": [
        "## 8.9 データ準備2 (Transformsによるデータ前処理)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_LMC1gpORq6"
      },
      "source": [
        "### Step1 ToTensorの利用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JBDhjnIORq6"
      },
      "source": [
        "# ライブラリインポート\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform1 = transforms.Compose([\n",
        "    # データのTensor化\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_set1 = datasets.MNIST(\n",
        "    root=data_root,  train=True,  download=True,\n",
        "    transform = transform1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHERq6bDORq6"
      },
      "source": [
        "# 変換結果の確認\n",
        "\n",
        "image, label = train_set1[0]\n",
        "print('入力データの型: ', type(image))\n",
        "print('入力データのshape: ', image.shape)\n",
        "print('最小値: ', image.data.min())\n",
        "print('最大値: ', image.data.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc0HYDp_ORq7"
      },
      "source": [
        "### Step2 Normalizeの利用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGCtROV8ORq7"
      },
      "source": [
        "transform2 = transforms.Compose([\n",
        "    # データのTensor化\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    # データの正規化\n",
        "    transforms.Normalize(0.5,  0.5),\n",
        "])\n",
        "\n",
        "train_set2 = datasets.MNIST(\n",
        "    root = data_root,  train = True,  download = True,\n",
        "    transform = transform2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0R6AO1BORq7"
      },
      "source": [
        "# 変換結果の確認\n",
        "\n",
        "image, label = train_set2[0]\n",
        "print('shape: ', image.shape)\n",
        "print('最小値: ', image.data.min())\n",
        "print('最大値: ', image.data.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3cZ9aT9ORq8"
      },
      "source": [
        "### Step3 Lambdaを利用して1階テンソル化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsZ1B1MXORq8"
      },
      "source": [
        "transform3 = transforms.Compose([\n",
        "    # データのTensor化\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    # データの正規化\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "    \n",
        "    # Tensorの1階テンソル化\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "])\n",
        "\n",
        "train_set3 = datasets.MNIST(\n",
        "    root = data_root,  train = True,  \n",
        "    download=True, transform = transform3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQFnaPTnORq8"
      },
      "source": [
        "# 変換結果の確認\n",
        "\n",
        "image, label = train_set3[0]\n",
        "print('shape: ', image.shape)\n",
        "print('最小値: ', image.data.min())\n",
        "print('最大値: ', image.data.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm2hP2TtORq9"
      },
      "source": [
        "### 最終的な実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LuXsts3ORq9"
      },
      "source": [
        "# データ変換用関数 Transforms\n",
        "# (1) Imageをテンソル化\n",
        "# (2) [0, 1]の範囲の値を[-1, 1]の範囲にする\n",
        "# (3) データのshapeを[1, 28, 28]から[784]に変換\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # (1) データのテンソル化\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    # (2) データの正規化\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "    \n",
        "    # (3) 1階テンソルに変換\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gEppo6VORq9"
      },
      "source": [
        "# データ取得用関数 Dataset\n",
        "\n",
        "# 訓練用データセットの定義\n",
        "train_set = datasets.MNIST(\n",
        "    root = data_root, train = True,\n",
        "    download = True, transform = transform)\n",
        "\n",
        "# 検証データセットの定義\n",
        "test_set = datasets.MNIST(\n",
        "    root = data_root, train = False, \n",
        "    download = True, transform = transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE2YPjEFORq-"
      },
      "source": [
        "## 8.10 データ準備3 データローダーによるミニバッチ用データ生成)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Jog4MHORq-"
      },
      "source": [
        "# ライブラリインポート\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ミニバッチのサイズ指定\n",
        "batch_size = 500\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(\n",
        "    train_set, batch_size = batch_size, \n",
        "    shuffle = True)\n",
        "\n",
        "# 検証用データローダー\n",
        "# 検証時にシャッフルは不要\n",
        "test_loader = DataLoader(\n",
        "    test_set,  batch_size = batch_size, \n",
        "    shuffle = False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpWvs4n9ORq-"
      },
      "source": [
        "# 何組のデータが取得できるか\n",
        "print(len(train_loader))\n",
        "\n",
        "# DataLoaderから最初の1セットを取得する\n",
        "for images, labels in train_loader:\n",
        "    break\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIk15hXpORq_"
      },
      "source": [
        "# イメージ表示\n",
        "plt.figure(figsize=(10, 3))\n",
        "for i in range(20):\n",
        "    ax = plt.subplot(2, 10, i + 1)\n",
        "    \n",
        "    # numpyに変換\n",
        "    image = images[i].numpy()\n",
        "    label = labels[i]\n",
        "    \n",
        "    # imgの範囲を[0, 1]に戻す\n",
        "    image2 = (image + 1)/ 2\n",
        "    # イメージ表示\n",
        "    plt.imshow(image2.reshape(28, 28),cmap='gray_r')\n",
        "    ax.set_title(f'{label}')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C68aEOhrGyNA"
      },
      "source": [
        "全体で60000件ある訓練データが120個のグループに分割されて取得できていることがわかります。  \n",
        "今回はテスト用でシャッフルなしでデータを取得しましたが、訓練データは取得のたびにシャッフルがかかります。  \n",
        "つまり、ミニバッチ用のデータセットが自動的に取得できていることになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBHL-ynpTx6X"
      },
      "source": [
        "## 8.11 モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIXhfySWTx6Y"
      },
      "source": [
        "# 入力次元数\n",
        "n_input = image.shape[0]\n",
        "\n",
        "# 出力次元数\n",
        "# 分類先クラス数　今回は10になる\n",
        "n_output = 10\n",
        "\n",
        "#   隠れ層のノード数\n",
        "n_hidden = 128\n",
        "\n",
        "# 結果確認\n",
        "print(f'n_input: {n_input}  n_hidden: {n_hidden} n_output: {n_output}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIHt22OFGyNC"
      },
      "source": [
        "# モデルの定義\n",
        "# 784入力10出力1隠れ層のニューラルネットワークモデル\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output, n_hidden):\n",
        "        super().__init__()\n",
        "\n",
        "        # 隠れ層の定義 (隠れ層のノード数: n_hidden)\n",
        "        self.l1 = nn.Linear(n_input, n_hidden)\n",
        "\n",
        "        # 出力層の定義\n",
        "        self.l2 = nn.Linear(n_hidden, n_output)\n",
        "\n",
        "        # ReLU関数の定義\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "   \n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        x2 = self.relu(x1)\n",
        "        x3 = self.l2(x2)\n",
        "        return x3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q749IwhKGyNC"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = Net(n_input, n_output, n_hidden)\n",
        "\n",
        "# モデルをGPU側に送る\n",
        "net = net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V6v9PCpTx6b"
      },
      "source": [
        "### 最適化アルゴリズムと損失関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyIXY4i_GyNC"
      },
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# アルゴリズム: 勾配降下法\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdR3zTewTx6c"
      },
      "source": [
        "### モデル確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDwhdRWjMOmT"
      },
      "source": [
        "# モデル内のパラメータの確認\n",
        "# l1.weight, l1.bias, l2.weight, l2.biasがあることがわかる\n",
        "\n",
        "for parameter in net.named_parameters():\n",
        "    print(parameter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b56fYbaVGyND"
      },
      "source": [
        "# モデルの概要表示\n",
        "\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl6x8W1vGyND"
      },
      "source": [
        "# モデルのサマリー表示\n",
        "\n",
        "summary(net, (784,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zodDP4VcuuQl"
      },
      "source": [
        "## 8.12 勾配降下法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnhTGUUiBYnV"
      },
      "source": [
        "### 予測計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE5l-chbGyND"
      },
      "source": [
        "# 訓練データセット　最初の1項目を取得\n",
        "# データローダーから最初の1セットを取得する\n",
        "for images, labels in train_loader:\n",
        "    break "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQax9NwFJeWs"
      },
      "source": [
        "# データローダーから取得したデータをGPUに送る\n",
        "inputs = images.to(device)\n",
        "labels = labels.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZWIl2PUJl8B"
      },
      "source": [
        "# 予測計算\n",
        "outputs = net(inputs)\n",
        "\n",
        "# 結果確認\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7D1YeAxBsD_"
      },
      "source": [
        "### 損失関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PbP_nUUDsJZ"
      },
      "source": [
        "#### 損失計算と計算グラフの可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-2E8cA_d4dF"
      },
      "source": [
        "#  損失計算\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "# 損失値の取得\n",
        "print(loss.item())\n",
        "\n",
        "# 損失の計算グラフ可視化\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZKkOTDbByWr"
      },
      "source": [
        "### 勾配計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTvRimoEiHeZ"
      },
      "source": [
        "# 勾配計算の実行\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xRXQnfsArTV"
      },
      "source": [
        "# 勾配計算の結果\n",
        "w = net.to('cpu')\n",
        "print(w.l1.weight.grad.numpy())\n",
        "print(w.l1.bias.grad.numpy())\n",
        "print(w.l2.weight.grad.numpy())\n",
        "print(w.l2.bias.grad.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAN6zrWwB_1Q"
      },
      "source": [
        "### パラメータ修正"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-fIWFp7iW8_"
      },
      "source": [
        "# 勾配降下法の適用\n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quuVCRNJij0M"
      },
      "source": [
        "# パラメータ値の表示\n",
        "print(net.l1.weight)\n",
        "print(net.l1.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fuqiacmvNJq"
      },
      "source": [
        "### 繰り返し計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_xGv4kci7XG"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms = True\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = Net(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 100\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8e4FfOLfFV4"
      },
      "source": [
        "# tqdmライブラリのインポート\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# 繰り返し計算メインループ\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 1エポックあたりの正解数(精度計算用)\n",
        "    n_train_acc, n_val_acc = 0, 0\n",
        "    # 1エポックあたりの累積損失(平均化前)\n",
        "    train_loss, val_loss = 0, 0\n",
        "    # 1エポックあたりのデータ累積件数\n",
        "    n_train, n_test = 0, 0\n",
        "\n",
        "    # 訓練フェーズ\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        # 1バッチあたりのデータ件数\n",
        "        train_batch_size = len(labels)\n",
        "        # 1エポックあたりのデータ累積件数\n",
        "        n_train += train_batch_size\n",
        "\n",
        "        # GPUヘ転送\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "    \n",
        "        #勾配の初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 予測計算\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # 損失計算\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 勾配計算\n",
        "        loss.backward()\n",
        "    \n",
        "        # パラメータ修正\n",
        "        optimizer.step()\n",
        "\n",
        "        # 予測ラベル導出\n",
        "        predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "        # 平均前の損失と正解数の計算\n",
        "        # lossは平均計算が行われているので平均前の損失に戻して加算\n",
        "        train_loss += loss.item() * train_batch_size \n",
        "        n_train_acc += (predicted == labels).sum().item() \n",
        "\n",
        "    #予測フェーズ\n",
        "    for inputs_test, labels_test in test_loader:\n",
        "        # 1バッチあたりのデータ件数\n",
        "        test_batch_size = len(labels_test)\n",
        "        # 1エポックあたりのデータ累積件数\n",
        "        n_test += test_batch_size\n",
        "\n",
        "        inputs_test = inputs_test.to(device)\n",
        "        labels_test = labels_test.to(device)\n",
        "            \n",
        "        # 予測計算\n",
        "        outputs_test = net(inputs_test)\n",
        "\n",
        "        # 損失計算\n",
        "        loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "        #予測ラベル導出\n",
        "        predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "        #  平均前の損失と正解数の計算\n",
        "        # lossは平均計算が行われているので平均前の損失に戻して加算\n",
        "        val_loss +=  loss_test.item() * test_batch_size\n",
        "        n_val_acc +=  (predicted_test == labels_test).sum().item()\n",
        "\n",
        "    # 精度計算\n",
        "    train_acc = n_train_acc / n_train\n",
        "    val_acc = n_val_acc / n_test\n",
        "    # 損失計算\n",
        "    ave_train_loss = train_loss / n_train\n",
        "    ave_val_loss = val_loss / n_test\n",
        "    # 結果表示\n",
        "    print (f'Epoch [{epoch+1}/{num_epochs}], loss: {ave_train_loss:.5f} acc: {train_acc:.5f} val_loss: {ave_val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "    # 記録\n",
        "    item = np.array([epoch+1 , ave_train_loss, train_acc, ave_val_loss, val_acc])\n",
        "    history = np.vstack((history, item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YpNqlm2vZC0"
      },
      "source": [
        "## 8.13 結果確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NQJM_UBli5m"
      },
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phCQdH7No5Z_"
      },
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (9,8)\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3I8Jw0ticf2"
      },
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (9,8)\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHbKGRzI9XWn"
      },
      "source": [
        "### イメージ表示で確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVuuBxXWHNvE"
      },
      "source": [
        "# DataLoaderから最初の1セットを取得する\n",
        "for images, labels in test_loader:\n",
        "    break\n",
        "\n",
        "# 予測結果の取得\n",
        "inputs = images.to(device)\n",
        "labels = labels.to(device)\n",
        "outputs = net(inputs)\n",
        "predicted = torch.max(outputs, 1)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN5MGTud7bsf"
      },
      "source": [
        "# 最初の50件でイメージを「正解値:予測値」と表示\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(50):\n",
        "  ax = plt.subplot(5, 10, i + 1)\n",
        "    \n",
        "  # numpyに変換\n",
        "  image = images[i]\n",
        "  label = labels[i]\n",
        "  pred = predicted[i]\n",
        "  if (pred == label):\n",
        "    c = 'k'\n",
        "  else:\n",
        "    c = 'b'\n",
        "    \n",
        "  # imgの範囲を[0, 1]に戻す\n",
        "  image2 = (image + 1)/ 2\n",
        "    \n",
        "  # イメージ表示\n",
        "  plt.imshow(image2.reshape(28, 28),cmap='gray_r')\n",
        "  ax.set_title(f'{label}:{pred}', c=c)\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYQlrBNW4b0R"
      },
      "source": [
        "## 8.14 隠れ層の2層化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKI_YKqevw16"
      },
      "source": [
        "# モデルの定義\n",
        "# 784入力10出力2隠れ層のニューラルネットワークモデル\n",
        "\n",
        "class Net2(nn.Module):\n",
        "    def __init__(self, n_input, n_output, n_hidden):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 隠れ層1の定義 (隠れ層のノード数: n_hidden)\n",
        "        self.l1 = nn.Linear(n_input, n_hidden)\n",
        "\n",
        "        # 隠れ層2の定義 (隠れ層のノード数: n_hidden)\n",
        "        self.l2 = nn.Linear(n_hidden, n_hidden)\n",
        "\n",
        "        # 出力層の定義\n",
        "        self.l3 = nn.Linear(n_hidden, n_output)\n",
        "\n",
        "        # ReLU関数の定義\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        x2 = self.relu(x1)\n",
        "        x3 = self.l2(x2)\n",
        "        x4 = self.relu(x3)\n",
        "        x5 = self.l3(x4)\n",
        "        return x5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iZ_1fHl59Js"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = Net2(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6iqjM5P5EW5"
      },
      "source": [
        "# モデルの概要表示\n",
        "\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL5pmOzi5T0i"
      },
      "source": [
        "# モデルのサマリー表示\n",
        "\n",
        "summary(net, (784,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuznoi_AgBQ0"
      },
      "source": [
        "# DataLoaderから最初の1セットを取得する\n",
        "for images, labels in test_loader:\n",
        "    break\n",
        "\n",
        "# 予測結果の取得\n",
        "inputs = images.to(device)\n",
        "labels = labels.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANTVr2Wz5bbU"
      },
      "source": [
        "# 予測計算\n",
        "outputs = net(inputs)\n",
        "\n",
        "#  損失計算\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "# 損失の計算グラフ可視化\n",
        "make_dot(loss, params=dict(net.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSvDarxnQRbh"
      },
      "source": [
        "### 勾配計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqzLuvQ3ix3t"
      },
      "source": [
        "# 勾配計算\n",
        "loss.backward()\n",
        "\n",
        "# 勾配計算結果の一部\n",
        "w = net.to('cpu').l1.weight.grad.numpy()\n",
        "print(w)\n",
        "\n",
        "# 各要素の絶対値の平均\n",
        "print(np.abs(w).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d8Wavl7rehD"
      },
      "source": [
        "### 繰り返し計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y4-Y2KA602e"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms = True\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = Net2(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 200\n",
        "\n",
        "# 評価結果記録用\n",
        "history2 = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tqdmライブラリのインポート\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# 繰り返し計算メインループ\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 1エポックあたりの正解数(精度計算用)\n",
        "    n_train_acc, n_val_acc = 0, 0\n",
        "    # 1エポックあたりの累積損失(平均化前)\n",
        "    train_loss, val_loss = 0, 0\n",
        "    # 1エポックあたりのデータ累積件数\n",
        "    n_train, n_test = 0, 0\n",
        "\n",
        "    # 訓練フェーズ\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        # 1バッチあたりのデータ件数\n",
        "        train_batch_size = len(labels)\n",
        "        # 1エポックあたりのデータ累積件数\n",
        "        n_train += train_batch_size\n",
        "\n",
        "        # GPUヘ転送\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "    \n",
        "        #勾配の初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 予測計算\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # 損失計算\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 勾配計算\n",
        "        loss.backward()\n",
        "    \n",
        "        # パラメータ修正\n",
        "        optimizer.step()\n",
        "\n",
        "        # 予測ラベル導出\n",
        "        predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "        # 平均前の損失と正解数の計算\n",
        "        # lossは平均計算が行われているので平均前の損失に戻して加算\n",
        "        train_loss += loss.item() * train_batch_size \n",
        "        n_train_acc += (predicted == labels).sum().item() \n",
        "\n",
        "    #予測フェーズ\n",
        "    for inputs_test, labels_test in test_loader:\n",
        "        # 1バッチあたりのデータ件数\n",
        "        test_batch_size = len(labels_test)\n",
        "        # 1エポックあたりのデータ累積件数\n",
        "        n_test += test_batch_size\n",
        "\n",
        "        inputs_test = inputs_test.to(device)\n",
        "        labels_test = labels_test.to(device)\n",
        "            \n",
        "        # 予測計算\n",
        "        outputs_test = net(inputs_test)\n",
        "\n",
        "        # 損失計算\n",
        "        loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "        #予測ラベル導出\n",
        "        predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "        #  平均前の損失と正解数の計算\n",
        "        # lossは平均計算が行われているので平均前の損失に戻して加算\n",
        "        val_loss +=  loss_test.item() * test_batch_size\n",
        "        n_val_acc +=  (predicted_test == labels_test).sum().item()\n",
        "\n",
        "    # 精度計算\n",
        "    train_acc = n_train_acc / n_train\n",
        "    val_acc = n_val_acc / n_test\n",
        "    # 損失計算\n",
        "    ave_train_loss = train_loss / n_train\n",
        "    ave_val_loss = val_loss / n_test\n",
        "    # 結果表示\n",
        "    print (f'Epoch [{epoch+1}/{num_epochs}], loss: {ave_train_loss:.5f} acc: {train_acc:.5f} val_loss: {ave_val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "    # 記録\n",
        "    item = np.array([epoch+1 , ave_train_loss, train_acc, ave_val_loss, val_acc])\n",
        "    history2 = np.vstack((history2, item))"
      ],
      "metadata": {
        "id": "3S5NlNuoXi2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypvzwuju7Imp"
      },
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history2[0,3]:.5f} 精度: {history2[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history2[-1,3]:.5f} 精度: {history2[-1,4]:.5f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTvso0I27I2a"
      },
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history2[:,0], history2[:,1], 'b', label='訓練')\n",
        "plt.plot(history2[:,0], history2[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5qoasEA7JEa"
      },
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history2[:,0], history2[:,2], 'b', label='訓練')\n",
        "plt.plot(history2[:,0], history2[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW9O1YawQRbq"
      },
      "source": [
        "## コラム　勾配消失とReLU関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAyrUWNFQRbq"
      },
      "source": [
        "# モデルの定義　シグモイド関数バージョン\n",
        "# 784入力10出力2隠れ層のニューラルネットワークモデル\n",
        "\n",
        "class Net3(nn.Module):\n",
        "    def __init__(self, n_input, n_output, n_hidden):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 隠れ層1の定義 (隠れ層のノード数: n_hidden)\n",
        "        self.l1 = nn.Linear(n_input, n_hidden)\n",
        "\n",
        "        # 隠れ層2の定義 (隠れ層のノード数: n_hidden)\n",
        "        self.l2 = nn.Linear(n_hidden, n_hidden)\n",
        "\n",
        "        # 出力層の定義\n",
        "        self.l3 = nn.Linear(n_hidden, n_output)\n",
        "\n",
        "        # シグモイド関数の定義\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        x2 = self.sigmoid(x1)\n",
        "        x3 = self.l2(x2)\n",
        "        x4 = self.sigmoid(x3)\n",
        "        x5 = self.l3(x4)\n",
        "        return x5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Eh3LoaBQRbr"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = Net3(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jZIRBRSfsov"
      },
      "source": [
        "# DataLoaderから最初の1セットを取得する\n",
        "for images, labels in test_loader:\n",
        "    break\n",
        "\n",
        "# 予測結果の取得\n",
        "inputs = images.to(device)\n",
        "labels = labels.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1OMhGtkmkR5"
      },
      "source": [
        "# 予測計算\n",
        "outputs = net(inputs)\n",
        "\n",
        "# 損失計算\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "# 損失の計算グラフ可視化\n",
        "make_dot(loss, params=dict(net.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxF0mwu8HTuK"
      },
      "source": [
        "# 勾配計算\n",
        "loss.backward()\n",
        "\n",
        "# 勾配計算結果の一部\n",
        "w = net.to('cpu').l1.weight.grad.numpy()\n",
        "print(w)\n",
        "\n",
        "# 各要素の絶対値の平均\n",
        "print(np.abs(w).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l27mdkndXTYK"
      },
      "source": [
        "## コラム　lambda式による関数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHF-e5roXToO"
      },
      "source": [
        "# 通常の関数定義\n",
        "\n",
        "def f(x):\n",
        "    return (2 * x**2 + 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV8-PErUztA0"
      },
      "source": [
        "x = np.arange(-2, 2.1, 0.25)\n",
        "y = f(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G78qvPjztA0"
      },
      "source": [
        "# lambda式による関数定義\n",
        "\n",
        "g = lambda x: 2 * x**2 + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G6B3TKkztA0"
      },
      "source": [
        "y = g(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcZ6_XudTXJe"
      },
      "source": [
        "## コラム バッチサイズと精度"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj1K95OlGa2I"
      },
      "source": [
        "### fit関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習用関数\n",
        "def fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history):\n",
        "\n",
        "    # tqdmライブラリのインポート\n",
        "    from tqdm.notebook import tqdm\n",
        "\n",
        "    base_epochs = len(history)\n",
        "  \n",
        "    for epoch in range(base_epochs, num_epochs+base_epochs):\n",
        "        # 1エポックあたりの正解数(精度計算用)\n",
        "        n_train_acc, n_val_acc = 0, 0\n",
        "        # 1エポックあたりの累積損失(平均化前)\n",
        "        train_loss, val_loss = 0, 0\n",
        "        # 1エポックあたりのデータ累積件数\n",
        "        n_train, n_test = 0, 0\n",
        "\n",
        "        #訓練フェーズ\n",
        "        net.train()\n",
        "\n",
        "        for inputs, labels in tqdm(train_loader):\n",
        "            # 1バッチあたりのデータ件数\n",
        "            train_batch_size = len(labels)\n",
        "            # 1エポックあたりのデータ累積件数\n",
        "            n_train += train_batch_size\n",
        "    \n",
        "            # GPUヘ転送\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 勾配の初期化\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 予測計算\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            # 損失計算\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 勾配計算\n",
        "            loss.backward()\n",
        "\n",
        "            # パラメータ修正\n",
        "            optimizer.step()\n",
        "\n",
        "            # 予測ラベル導出\n",
        "            predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "            # 平均前の損失と正解数の計算\n",
        "            # lossは平均計算が行われているので平均前の損失に戻して加算\n",
        "            train_loss += loss.item() * train_batch_size \n",
        "            n_train_acc += (predicted == labels).sum().item() \n",
        "\n",
        "        #予測フェーズ\n",
        "        net.eval()\n",
        "\n",
        "        for inputs_test, labels_test in test_loader:\n",
        "            # 1バッチあたりのデータ件数\n",
        "            test_batch_size = len(labels_test)\n",
        "            # 1エポックあたりのデータ累積件数\n",
        "            n_test += test_batch_size\n",
        "\n",
        "            # GPUヘ転送\n",
        "            inputs_test = inputs_test.to(device)\n",
        "            labels_test = labels_test.to(device)\n",
        "\n",
        "            # 予測計算\n",
        "            outputs_test = net(inputs_test)\n",
        "\n",
        "            # 損失計算\n",
        "            loss_test = criterion(outputs_test, labels_test)\n",
        " \n",
        "            # 予測ラベル導出\n",
        "            predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "            #  平均前の損失と正解数の計算\n",
        "            # lossは平均計算が行われているので平均前の損失に戻して加算\n",
        "            val_loss +=  loss_test.item() * test_batch_size\n",
        "            n_val_acc +=  (predicted_test == labels_test).sum().item()\n",
        "\n",
        "        # 精度計算\n",
        "        train_acc = n_train_acc / n_train\n",
        "        val_acc = n_val_acc / n_test\n",
        "        # 損失計算\n",
        "        avg_train_loss = train_loss / n_train\n",
        "        avg_val_loss = val_loss / n_test\n",
        "        # 結果表示\n",
        "        print (f'Epoch [{(epoch+1)}/{num_epochs+base_epochs}], loss: {avg_train_loss:.5f} acc: {train_acc:.5f} val_loss: {avg_val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        # 記録\n",
        "        item = np.array([epoch+1, avg_train_loss, train_acc, avg_val_loss, val_acc])\n",
        "        history = np.vstack((history, item))\n",
        "    return history"
      ],
      "metadata": {
        "id": "Q5yVM-xLYhjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzdXGNUYM_sk"
      },
      "source": [
        "# PyTorch乱数固定用\n",
        "\n",
        "def torch_seed(seed=123):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rq82O2Ti87J"
      },
      "source": [
        "# ミニバッチのサイズ指定\n",
        "batch_size_train = 500\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(\n",
        "    train_set, batch_size = batch_size_train, \n",
        "    shuffle = True)\n",
        "\n",
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = Net(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 100\n",
        "\n",
        "# 評価結果記録用\n",
        "history6 = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr8JBupxjOaj"
      },
      "source": [
        "history6 = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt295NtfX_HK"
      },
      "source": [
        "### batch_size=200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSDG1UhbTuk4"
      },
      "source": [
        "# ミニバッチのサイズ指定\n",
        "batch_size_train = 200\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(\n",
        "    train_set, batch_size = batch_size_train, \n",
        "    shuffle = True)\n",
        "\n",
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = Net(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 100\n",
        "\n",
        "# 評価結果記録用\n",
        "history3 = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4ozAKcH7v2"
      },
      "source": [
        "history3 = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whmV7NaLIyJE"
      },
      "source": [
        "### batch_size=100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90I9xU_SIu_v"
      },
      "source": [
        "# ミニバッチのサイズ指定\n",
        "batch_size_train = 100\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(\n",
        "    train_set, batch_size = batch_size_train, \n",
        "    shuffle = True)\n",
        "\n",
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# モデル初期化\n",
        "net = Net(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 100\n",
        "\n",
        "# 評価結果記録用\n",
        "history4 = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FVIZ5U9IvF0"
      },
      "source": [
        "history4 = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY58TdCuJBrR"
      },
      "source": [
        "### batch_size=50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsDDyUh7IvNb"
      },
      "source": [
        "# ミニバッチのサイズ指定\n",
        "batch_size_train = 50\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(\n",
        "    train_set, batch_size = batch_size_train, \n",
        "    shuffle = True)\n",
        "\n",
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# モデル初期化\n",
        "net = Net(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 100\n",
        "\n",
        "# 評価結果記録用\n",
        "history5 = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BEa8fHvIvoZ"
      },
      "source": [
        "history5 = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bJR1IpmJpGh"
      },
      "source": [
        "### 学習曲線の比較"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6wENwdCorRu"
      },
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,4], label='batch_size=500', c='k', linestyle='-.')\n",
        "plt.plot(history3[:,0], history3[:,4], label='batch_size=200', c='b', linestyle='-.')\n",
        "plt.plot(history4[:,0], history4[:,4], label='batch_size=100', c='k')\n",
        "plt.plot(history5[:,0], history5[:,4], label='batch_size=50', c='b')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCLl1jfqcjVQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}