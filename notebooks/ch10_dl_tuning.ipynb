{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ch10_dl_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckLcJPHZqaj-"
      },
      "source": [
        "# 10章 チューニング技法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-6qx6_7qSw_"
      },
      "source": [
        "# 必要ライブラリの導入\n",
        "\n",
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st5zXZGKqeZq"
      },
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiaarQ74qrgy"
      },
      "source": [
        "# PyTorch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.datasets as datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us8Dby1Equ2D"
      },
      "source": [
        "# warning表示off\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whKFXDu5qzTr"
      },
      "source": [
        "# GPUチェック\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEmsU7U3rpWf"
      },
      "source": [
        "# 分類先クラスの名称リスト\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# 分類先クラス数　今回は10になる\n",
        "n_output = len(list(set(classes)))\n",
        "\n",
        "# 結果確認\n",
        "print(n_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zfeyyfk0Kvv"
      },
      "source": [
        "## 10.4 過学習とその対応"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goWAaHpk0Kvv"
      },
      "source": [
        "### ドロップアウト関数の動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiFb6qkF0Kvv"
      },
      "source": [
        "# ドロップアウトテスト用ダミーデータの作成\n",
        "\n",
        "torch.manual_seed(123)\n",
        "inputs = torch.randn(1, 10)\n",
        "print(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rftztSp80Kvw"
      },
      "source": [
        "# dropout関数の定義\n",
        "dropout = nn.Dropout(0.5)\n",
        "\n",
        "# 訓練フェーズでの挙動\n",
        "dropout.train()\n",
        "print(dropout.training)\n",
        "outputs = dropout(inputs)\n",
        "print(outputs)\n",
        "\n",
        "# 予測フェーズでの挙動\n",
        "dropout.eval()\n",
        "print(dropout.training)\n",
        "outputs = dropout(inputs)\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAGFmh9YrFWO"
      },
      "source": [
        "## 10.5 共通関数のライブラリ化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEn1clT_q2ro"
      },
      "source": [
        "# 共通関数のダウンロード\n",
        "!git clone https://github.com/makaishi2/pythonlibs.git\n",
        "\n",
        "# 共通関数のロード\n",
        "from pythonlibs.torch_lib1 import *\n",
        "\n",
        "# 共通関数の存在チェック\n",
        "print(README)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yz6QdI-rQP-"
      },
      "source": [
        "## データ準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuvxpoAXrLwg"
      },
      "source": [
        "# Transformsの定義\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(0.5, 0.5)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRYkRgTWrart"
      },
      "source": [
        "# データ取得用関数 Dataset\n",
        "\n",
        "data_root = './data'\n",
        "\n",
        "train_set = datasets.CIFAR10(\n",
        "    root = data_root, train = True, \n",
        "    download = True, transform = transform)\n",
        "\n",
        "# 検証データの取得\n",
        "test_set = datasets.CIFAR10(\n",
        "    root = data_root, train = False, \n",
        "    download = True, transform = transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzx_dlTwria6"
      },
      "source": [
        "# ミニバッチのサイズ指定\n",
        "batch_size = 100\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(train_set, \n",
        "    batch_size = batch_size, shuffle = True)\n",
        "\n",
        "# 検証用データローダー\n",
        "# 検証時にシャッフルは不要\n",
        "test_loader = DataLoader(test_set,  \n",
        "    batch_size = batch_size, shuffle = False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUeMHynYfeXM"
      },
      "source": [
        "# 最初の50個の表示\n",
        "show_images_labels(test_loader, classes, None, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74QYRZ5VrvZ8"
      },
      "source": [
        "## 10.6 階層を深くしたモデルの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnXgAmaGpfwp"
      },
      "source": [
        "class CNN_v2(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1))\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.maxpool = nn.MaxPool2d((2,2))\n",
        "        self.l1 = nn.Linear(4*4*128, 128)\n",
        "        self.l2 = nn.Linear(128, num_classes)\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.relu,\n",
        "            self.conv2,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.conv3,\n",
        "            self.relu,\n",
        "            self.conv4,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.conv5,\n",
        "            self.relu,\n",
        "            self.conv6,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            self.l1,\n",
        "            self.relu,\n",
        "            self.l2\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.features(x)\n",
        "        x2 = self.flatten(x1)\n",
        "        x3 = self.classifier(x2)\n",
        "        return x3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmGI6snCSMzK"
      },
      "source": [
        "# 損失関数のグラフ表示\n",
        "net = CNN_v2(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = eval_loss(test_loader, device, net, criterion)\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHtdQiN_s7Jr"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# モデルインスタンス生成\n",
        "lr = 0.01\n",
        "net = CNN_v2(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "history = np.zeros((0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9iKlidP9jYa"
      },
      "source": [
        "# 学習\n",
        "\n",
        "num_epochs = 50\n",
        "history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCUJe6PM2PI7"
      },
      "source": [
        "evaluate_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV790UUcu3FT"
      },
      "source": [
        "## 10.7 最適化関数の選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qTrh0NmvE6S"
      },
      "source": [
        "### momentumの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Dcw2OEu8Ew"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# モデルインスタンス生成\n",
        "lr = 0.01\n",
        "net = CNN_v2(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 最適化関数にmomentumを指定\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
        "history2 = np.zeros((0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0fS7glergiY"
      },
      "source": [
        "# 学習\n",
        "\n",
        "num_epochs = 20\n",
        "history2 = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI5ceW1RVLFx"
      },
      "source": [
        "evaluate_history(history2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE2SYfxyvhJ6"
      },
      "source": [
        "### Adamの利用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bKK7XrSvfi3"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = CNN_v2(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 最適化関数にAdamを指定\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "history3 = np.zeros((0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIHfMQ0e2g39"
      },
      "source": [
        "print(optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ng2-Z9nvsZK"
      },
      "source": [
        "# 学習\n",
        "\n",
        "num_epochs = 20\n",
        "history3 = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuHMfaGOVXyg"
      },
      "source": [
        "evaluate_history(history3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aed36ITYjP8"
      },
      "source": [
        "### 結果比較"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__RXzITNPk96"
      },
      "source": [
        "# 結果の比較(検証データへの精度)\n",
        "plt.figure(figsize=(9,8))\n",
        "plt.plot(history[:,0], history[:,4], label='SGD', c='k',ls='dashed' )\n",
        "plt.plot(history2[:,0], history2[:,4], label='SGD momentum=0.9', c='k')\n",
        "plt.plot(history3[:,0], history3[:,4], label='Adam', c='b')\n",
        "plt.title('最適化関数　比較結果（検証データへの精度）')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr2klUXH5bTA"
      },
      "source": [
        "## 10.8 ドロップアウト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qltVciI85iDd"
      },
      "source": [
        "# 予測クラスの定義\n",
        "\n",
        "class CNN_v3(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1))\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.maxpool = nn.MaxPool2d((2,2))\n",
        "        self.l1 = nn.Linear(4*4*128, 128)\n",
        "        self.l2 = nn.Linear(128, num_classes)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.dropout3 = nn.Dropout(0.4)\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.relu,\n",
        "            self.conv2,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout1,\n",
        "            self.conv3,\n",
        "            self.relu,\n",
        "            self.conv4,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout2,\n",
        "            self.conv5,\n",
        "            self.relu,\n",
        "            self.conv6,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout3,\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            self.l1,\n",
        "            self.relu,\n",
        "            self.dropout3,\n",
        "            self.l2\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.features(x)\n",
        "        x2 = self.flatten(x1)\n",
        "        x3 = self.classifier(x2)\n",
        "        return x3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg7ksBy7aPM9"
      },
      "source": [
        "# 損失関数のグラフ表示\n",
        "net = CNN_v3(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = eval_loss(test_loader, device, net, criterion)\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCLPJKOB5iKI"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = CNN_v3(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "history = np.zeros((0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8IAq6yLQXRS"
      },
      "source": [
        "# 学習\n",
        "\n",
        "num_epochs = 50\n",
        "history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJd7D_fj4lPY"
      },
      "source": [
        "evaluate_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPEhkwrR9akt"
      },
      "source": [
        "## 10.9 Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_7ECYZT9Pdu"
      },
      "source": [
        "class CNN_v4(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1))\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.maxpool = nn.MaxPool2d((2,2))\n",
        "        self.l1 = nn.Linear(4*4*128, 128)\n",
        "        self.l2 = nn.Linear(128, num_classes)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.dropout3 = nn.Dropout(0.4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.bn1,\n",
        "            self.relu,\n",
        "            self.conv2,\n",
        "            self.bn2,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout1,\n",
        "            self.conv3,\n",
        "            self.bn3,\n",
        "            self.relu,\n",
        "            self.conv4,\n",
        "            self.bn4,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout2,\n",
        "            self.conv5,\n",
        "            self.bn5,\n",
        "            self.relu,\n",
        "            self.conv6,\n",
        "            self.bn6,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout3,\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            self.l1,\n",
        "            self.relu,\n",
        "            self.dropout3,\n",
        "            self.l2\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.features(x)\n",
        "        x2 = self.flatten(x1)\n",
        "        x3 = self.classifier(x2)\n",
        "        return x3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5OqNcyW9ZN4"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = CNN_v4(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "history = np.zeros((0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWACh_ciUINH"
      },
      "source": [
        "# 学習\n",
        "\n",
        "num_epochs = 50\n",
        "history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk4bZw2n9Zdf"
      },
      "source": [
        "evaluate_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av3Bq3PJAoIi"
      },
      "source": [
        "## 10.10 Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EFJGN1-A2vF"
      },
      "source": [
        "# 訓練データ用: 正規化に追加で反転とRandomErasingを実施\n",
        "transform_train = transforms.Compose([\n",
        "  transforms.RandomHorizontalFlip(p=0.5), \n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(0.5, 0.5), \n",
        "  transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu0ntWJoA28U"
      },
      "source": [
        "# transfrom_trainを利用したデータセットの定義\n",
        "train_set2 = datasets.CIFAR10(\n",
        "    root = data_root, train = True, \n",
        "    download = True, transform = transform_train)\n",
        "\n",
        "# traisform_trainを利用したデータローダーの定義\n",
        "batch_size = 100\n",
        "train_loader2 = DataLoader(train_set2, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUL7TPJueYh7"
      },
      "source": [
        "# 新しい訓練用データの先頭50個を表示してみる\n",
        "\n",
        "# 乱数初期化\n",
        "torch_seed()\n",
        "\n",
        "show_images_labels(train_loader2, classes, None, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stLHneFaA3N8"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = CNN_v4(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "history = np.zeros((0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB3XDJ3KBZzK"
      },
      "source": [
        "# 学習\n",
        "# 同じモデルでtrain_loader2に変更\n",
        "\n",
        "num_epochs = 100\n",
        "history = fit(net, optimizer, criterion, num_epochs, \n",
        "        train_loader2, test_loader, device, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrxOoHsXtzN_"
      },
      "source": [
        "evaluate_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiU1x8rzjvpS"
      },
      "source": [
        "show_images_labels(test_loader, classes, net, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAo4faftGMEJ"
      },
      "source": [
        "# 間違えた38番目のデータを抽出\n",
        "for images, labels in test_loader:\n",
        "    break\n",
        "image = images[37]\n",
        "label = labels[37]\n",
        "\n",
        "# イメージを表示して確認\n",
        "plt.figure(figsize=(3,3))\n",
        "w = image.numpy().copy()\n",
        "w2 = np.transpose(w, (1, 2, 0))\n",
        "w3 = (w2 + 1)/2 \n",
        "plt.title(classes[label])\n",
        "plt.imshow(w3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-5Qg41zHhFZ"
      },
      "source": [
        "# 予測値を取得\n",
        "image = image.view(1, 3, 32, 32)\n",
        "image = image.to(device)\n",
        "output = net(image)\n",
        "\n",
        "# ラベル別の確率値を表示\n",
        "probs = torch.softmax(output, dim=1)\n",
        "probs_np = probs.data.to('cpu').numpy()[0]\n",
        "values = np.frompyfunc(lambda x: f'{x:.04f}', 1, 1)(probs_np)\n",
        "names = np.array(classes)\n",
        "tbl = np.array([names, values]).T\n",
        "print(tbl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "resBWhXg5vBW"
      },
      "source": [
        "## コラム　Batch Normalization利用上の注意点"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lJ1-UPA55dF"
      },
      "source": [
        "### ダメなクラス定義の例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_7GF3yTIq_I"
      },
      "source": [
        "class CNN_v5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1))\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.maxpool = nn.MaxPool2d((2,2))\n",
        "        self.l1 = nn.Linear(4*4*128, 128)\n",
        "        self.l2 = nn.Linear(128, num_classes)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.dropout3 = nn.Dropout(0.4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.bn1,\n",
        "            self.relu,\n",
        "            self.conv2,\n",
        "            self.bn1,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout1,\n",
        "            self.conv3,\n",
        "            self.bn2,\n",
        "            self.relu,\n",
        "            self.conv4,\n",
        "            self.bn2,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout2,\n",
        "            self.conv5,\n",
        "            self.bn3,\n",
        "            self.relu,\n",
        "            self.conv6,\n",
        "            self.bn3,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "            self.dropout3,\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            self.l1,\n",
        "            self.relu,\n",
        "            self.dropout3,\n",
        "            self.l2\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.features(x)\n",
        "        x2 = self.flatten(x1)\n",
        "        x3 = self.classifier(x2)\n",
        "        return x3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVD8MCxq6Jys"
      },
      "source": [
        "# 乱数の固定化\n",
        "torch_seed()\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = CNN_v5(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "history = np.zeros((0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqeix_Gu6rDD"
      },
      "source": [
        "# 学習\n",
        "\n",
        "num_epochs = 50\n",
        "history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Tpn3v96Ph1"
      },
      "source": [
        "# 損失の計算グラフ可視化\n",
        "net = CNN_v5(n_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = eval_loss(test_loader, device, net, criterion)\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFDbpYsB65a3"
      },
      "source": [
        "## コラム Batch Normlizationの処理内容"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTP1e1Zo0Kv3"
      },
      "source": [
        "# 入力用ダミーデータの作成\n",
        "\n",
        "torch.manual_seed(123)\n",
        "inputs = torch.randn(1, 1, 10)\n",
        "print(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XnjvptZ0Kv3"
      },
      "source": [
        "# 入力ミニバッチデータの統計量計算\n",
        "\n",
        "i_mean = inputs.mean()\n",
        "i_var = inputs.var(unbiased=True)\n",
        "i_std = inputs.std(unbiased=False)\n",
        "print(i_mean, i_std, i_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN-vxxi20Kv3"
      },
      "source": [
        "# BN関数の定義\n",
        "\n",
        "bn = nn.BatchNorm1d(1)\n",
        "print(bn.running_mean)\n",
        "print(bn.running_var)\n",
        "print(bn.weight.data)\n",
        "print(bn.bias.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzen80r10Kv3"
      },
      "source": [
        "# BN関数の疑似呼び出し\n",
        "\n",
        "bn.train()\n",
        "print('===訓練フェーズ1===')\n",
        "outputs1 = bn(inputs)\n",
        "print(outputs1.data)\n",
        "print(bn.running_mean)\n",
        "print(bn.running_var)\n",
        "\n",
        "bn.eval()\n",
        "print('===予測フェーズ1===')\n",
        "outputs2 = bn(inputs)\n",
        "print(outputs2.data)\n",
        "print(bn.running_mean)\n",
        "print(bn.running_var)\n",
        "\n",
        "bn.train()\n",
        "print('===訓練フェーズ2===')\n",
        "outputs3 = bn(inputs)\n",
        "print(outputs3.data)\n",
        "print(bn.running_mean)\n",
        "print(bn.running_var)\n",
        "\n",
        "bn.eval()\n",
        "print('===予測フェーズ2===')\n",
        "outputs4 = bn(inputs)\n",
        "print(outputs4.data)\n",
        "print(bn.running_mean)\n",
        "print(bn.running_var)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp4ZNim20Kv3"
      },
      "source": [
        "# 訓練フェーズの出力\n",
        "\n",
        "xt = (inputs - i_mean)/i_std * bn.weight + bn.bias\n",
        "print(xt.data)\n",
        "\n",
        "print(outputs1.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIa4V8_z0Kv3"
      },
      "source": [
        "# 予測フェーズの出力\n",
        "\n",
        "xp = (inputs-bn.running_mean)/torch.sqrt(bn.running_var)\n",
        "print(xp.data)\n",
        "\n",
        "print(outputs4.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDycotjs0Kv4"
      },
      "source": [
        "# running_meanとrunnung_varの計算式\n",
        "\n",
        "# 初期値\n",
        "mean0 = 0\n",
        "var0 = 1\n",
        "momentum = bn.momentum\n",
        "\n",
        "# 移動平均計算1回目\n",
        "mean1 = (1-momentum) * mean0 +  momentum * i_mean\n",
        "var1 = (1-momentum) * var0 +  momentum * i_var\n",
        "print(mean1, var1)\n",
        "\n",
        "# 移動平均計算2回目\n",
        "mean2 = (1-momentum) * mean1 +  momentum * i_mean\n",
        "var2 = (1-momentum) * var1 +  momentum * i_var\n",
        "print(mean2, var2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxKKix9N0Kv5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}