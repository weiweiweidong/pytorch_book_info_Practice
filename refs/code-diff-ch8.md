#### ch8 _dl.ipynb  の差分

( 行頭が「-」: 削除された行、行頭が「+」:追加された行)

```
@@ -1018,13 +1018,19 @@
         "# 繰り返し計算メインループ\n",
         "\n",
         "for epoch in range(num_epochs):\n",
-        "    train_acc, train_loss = 0, 0\n",
-        "    val_acc, val_loss = 0, 0\n",
+        "    # 1エポックあたりの正解数(精度計算用)\n",
+        "    n_train_acc, n_val_acc = 0, 0\n",
+        "    # 1エポックあたりの累積損失(平均化前)\n",
+        "    train_loss, val_loss = 0, 0\n",
+        "    # 1エポックあたりのデータ累積件数\n",
         "    n_train, n_test = 0, 0\n",
         "\n",
         "    # 訓練フェーズ\n",
         "    for inputs, labels in tqdm(train_loader):\n",
-        "        n_train += len(labels)\n",
+        "        # 1バッチあたりのデータ件数\n",
+        "        train_batch_size = len(labels)\n",
+        "        # 1エポックあたりのデータ累積件数\n",
+        "        n_train += train_batch_size\n",
         "\n",
         "        # GPUヘ転送\n",
         "        inputs = inputs.to(device)\n",
@@ -1048,17 +1054,20 @@
         "        # 予測ラベル導出\n",
         "        predicted = torch.max(outputs, 1)[1]\n",
         "\n",
-        "        # 損失と精度の計算\n",
-        "        train_loss += loss.item()\n",
-        "        train_acc += (predicted == labels).sum().item() \n",
+        "        # 平均前の損失と正解数の計算\n",
+        "        # lossは平均計算が行われているので平均前の損失に戻して加算\n",
+        "        train_loss += loss.item() * train_batch_size \n",
+        "        n_train_acc += (predicted == labels).sum().item() \n",
         "\n",
         "    #予測フェーズ\n",
         "    for inputs_test, labels_test in test_loader:\n",
-        "        n_test += len(labels_test)\n",
+        "        # 1バッチあたりのデータ件数\n",
+        "        test_batch_size = len(labels_test)\n",
+        "        # 1エポックあたりのデータ累積件数\n",
+        "        n_test += test_batch_size\n",
         "\n",
         "        inputs_test = inputs_test.to(device)\n",
         "        labels_test = labels_test.to(device)\n",
-        "\n",
         "            \n",
         "        # 予測計算\n",
         "        outputs_test = net(inputs_test)\n",
@@ -1069,17 +1078,21 @@
         "        #予測ラベル導出\n",
         "        predicted_test = torch.max(outputs_test, 1)[1]\n",
         "\n",
-        "        # 損失と精度の計算\n",
-        "        val_loss +=  loss_test.item()\n",
-        "        val_acc +=  (predicted_test == labels_test).sum().item()\n",
-        "\n",
-        "    # 評価値の算出・記録\n",
-        "    train_acc = train_acc / n_train\n",
-        "    val_acc = val_acc / n_test\n",
-        "    train_loss = train_loss * batch_size / n_train\n",
-        "    val_loss = val_loss * batch_size / n_test\n",
-        "    print (f'Epoch [{epoch+1}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
-        "    item = np.array([epoch+1 , train_loss, train_acc, val_loss, val_acc])\n",
+        "        #  平均前の損失と正解数の計算\n",
+        "        # lossは平均計算が行われているので平均前の損失に戻して加算\n",
+        "        val_loss +=  loss_test.item() * test_batch_size\n",
+        "        n_val_acc +=  (predicted_test == labels_test).sum().item()\n",
+        "\n",
+        "    # 精度計算\n",
+        "    train_acc = n_train_acc / n_train\n",
+        "    val_acc = n_val_acc / n_test\n",
+        "    # 損失計算\n",
+        "    ave_train_loss = train_loss / n_train\n",
+        "    ave_val_loss = val_loss / n_test\n",
+        "    # 結果表示\n",
+        "    print (f'Epoch [{epoch+1}/{num_epochs}], loss: {ave_train_loss:.5f} acc: {train_acc:.5f} val_loss: {ave_val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
+        "    # 記録\n",
+        "    item = np.array([epoch+1 , ave_train_loss, train_acc, ave_val_loss, val_acc])\n",
         "    history = np.vstack((history, item))"
       ],
       "execution_count": null,
```
