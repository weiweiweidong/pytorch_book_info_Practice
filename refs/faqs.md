### FAQ


|章-節|ページ  |質問　　　　　　　|回答|最終更新日|
|---|---|---|---|---|
|(全体)|(全体)|実習コードはAnacondaなどGoogle Colab以外の環境でも動きますか|不足ライブラリを調べて、追加導入できるのであれば原理的には可能です。但しscikit-learnなどのライブラリはバージョンが異なると振る舞いが変わることがあります。そういった問題が起きた場合には自力で対応する必要があります。Google Colabの場合、常に単一環境なのでこのような問題は起きません。<br>また、実践編の実習はGPUがないと処理に時間がかかり実用的でなくなりますが、ローカルPCの場合、GPUは使えないか使えてもセットアップが大変なケースが多いです。<br>これらの理由から、初心者にはGoogle Colabが勧めです。|2021-11-03|
|(全体)|(全体)|PyTorch v2.0でも動きますか|動作確認をしたところ、すべての実習コードが問題なく動作することが確認できています。<br>1点だけ5章 p.185 コード5-34で実行結果が紙面のように``tensor([0.])``などとならず``None``と表示されますがプログラム実行に支障はありません。<br>なお、2023-03-21時点でGoogle Colab上のPyTorchはv1.13.1です。Google Colabの環境がアップデートされる前にPyTorch 2.0を利用したい場合は、[著者のQiita記事](https://qiita.com/makaishi2/items/58a79eaf95abfe304070)などを参考としてください。|2023-03-24|
|2.4節|p.80|脚注の意味がわかりにくいです|図などを追加した、よりわかりやすい解説を[qiita](https://qiita.com/makaishi2/items/2c40fe43c01b35acb8c4)に記載しました。こちらを参照して下さい。|2021-11-03|
|6.7節|p.215|散布図の横軸・縦軸の項目がなぜこうなるのかがわかりません。|今回のようにscikit-learnのライブラリを用いてアイリス・データセットを読み込んだ際の、項目名とデータの対応は、例えば次のようにfeauure_names属性をprintすることでわかります。<br/><br/>```print(iris.feature_names)```<br/><br>```['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']```<br/><br/>このあとで<br/><br/>```x_data = iris.data[:100,:2]```<br/><br/>によって、項目を４つから２つに絞り込んでいます。この際、残されるのは0列と1列に該当する「sepal length」と「sepal width」です。|2023-01-20|
|7.8節|p.247|散布図の横軸・縦軸の項目がなぜこうなるのかがわかりません。|今回のようにscikit-learnのライブラリを用いてアイリス・データセットを読み込んだ際の、項目名とデータの対応は、例えば次のようにfeauure_names属性をprintすることでわかります。<br/><br/>```print(iris.feature_names)```<br/><br>```['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']```<br/><br/>このあとで<br/>```x_select = x_org[:,[0,2]]```<br/><br/>によって、項目を４つから２つに絞り込んでいます。この際、残されるのは0列と2列に該当する「sepal length」と「petal length」です。|2023-01-20|
|7.10節|p.255|コード7-10、7-11でmax関数のindicesの値がすべて0なのはなぜですか|``print(outputs)``とするとわかりますが、この段階で同一行のすべての要素は同じ値を取っています。このような条件の場合、max関数のindicesは最初に最大値にマッチした0を返す仕様になっています。<br>特定の行のすべての要素の値が同一なのは、この段階で線形関数は初期状態（未学習）であり、初期値としてすべての要素に1.0を設定していることによります。|2021-11-03|
|8.12節|p.312|繰り返し処理中の以下のコードの意味がわかりません<br>(紙面に解説がない部分)<br> ``train_loss = train_loss * batch_size / n_train``|この処理の段階では(batch_size)でグループ化された損失を算出し、すべてを加算しています。ここで上記「損失」とは何かをより詳細に見ていきます。すると、p.268 図7-15の数式②の部分で示されるように、データ件数(batch_size)で割り算された結果になっていることがわかります。この値に(batch_size)をかけ、更に全体の訓練データ件数(n_train)で割り直すことで、「全体の平均値」を意味する正しい「損失」が得られることになります。|2022-04-02|
| 9～12章 |(全体)|損失値が紙面と異なっていますがなぜですか|9章から12章では、損失値は共通関数(fit関数)で計算しています。バッチ学習法において、損失値の累積計算では、損失関数の出力値にバッチサイズをかけた値を対象にすべきです。しかし、本書発売時点の共通関数の実装ではこの点への考慮が漏れており、結果的に損失値の計算結果が不正確になっていました。<br/>　bGitHub上の共通関数を正しく実装し直し、9章の紙面を修正しました。一方、10章以降では紙幅の関係で、3刷以降でも、損失値や損失の学習曲線が本書発売時のままになっています。このため紙面とGoogle Colab上の実行結果が異なりますが、後者の方が正しいので、そのように読み替えてください。<br/>　また、以上の違いはすべて共通関数による損失値の計算結果にだけ起きるものです。モデルは意図した正しいものが本書発売時点から生成されており、精度などにも間違いはありません。|2023-03-24|







[メインページに戻る](../README.md)
